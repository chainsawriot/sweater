---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
  )
set.seed(46709394)
```

# sweater <img src="man/figures/sweater_logo.svg" align="right" height="200" />

<!-- badges: start -->
<!-- badges: end -->

The goal of sweater (**S**peedy **W**ord **E**mbedding **A**ssociation **T**est & **E**xtras using **R**) is to test for biases in word embeddings.

The package provides functions that are speedy. They are either implemented in C++, or are speedy but accurate approximation of the original implementation proposed by Caliskan et al (2017).

If your goal is to reproduce the analysis in Caliskan et al (2017), please consider using the [original Java program](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DX4VWP&version=2.0) or the R package [cbn](https://github.com/conjugateprior/cbn) by Lowe. To reproduce the analysis in Garg et al (2018), please consider using the [original Python program](https://github.com/nikhgarg/EmbeddingDynamicStereotypes).

This package provides extras.

## Installation

You can install the Github version of sweater with:

``` r
devtools::install_github("chainsawriot/sweater")
```

## Notation of a query

All tests in this package use the concept of queries (see Badilla et al., 2020) to study the biases in the input word embeddings `w`. This package uses the "STAB" notation from Brunet et al (2019).

All tests depend on two types of words. The first type, namely, `S` and `T`, is *target words* (or *neutral words* in Garg et al). These are words that **should** have no bias. For instance, the words such as "nurse" and "professor" can be used as target words to study the gender bias in word embeddings. One can also seperate these words into two sets, `S` and `T`, to group words by their perceived bias. For example, Caliskan et al. (2017) grouped target words into two groups: mathematics ("math", "algebra", "geometry", "calculus", "equations", "computation", "numbers", "addition") and arts ("poetry", "art", "dance", "literature", "novel", "symphony", "drama", "sculpture"). Please note that also `T` is not always required.

The second type, namely `A` and `B`, is *attribute words* (or *group words* in Garg et al). These are words with known properties in relation to the bias that one is studying. For example, Caliskan et al. (2017) used gender-related words such as "male", "man", "boy", "brother", "he", "him", "his", "son" to study gender bias. These words qualify as attribute words because we know they are related to a certain gender. `A` and `B` are always required.

All functions follow the same template: `test(w, S, T, A, B)`. One can then extract the effect size of the test using `test_es`.

## Example: Word Embedding Association Test

This example reproduces the detection of "Math. vs Arts" gender bias in Caliskan et al (2017).

```{r maths}
require(sweater)
data(glove_math) # a subset of the original GLoVE word vectors

S <- c("math", "algebra", "geometry", "calculus", "equations", "computation", "numbers", "addition")
T <- c("poetry", "art", "dance", "literature", "novel", "symphony", "drama", "sculpture")
A <- c("male", "man", "boy", "brother", "he", "him", "his", "son")
B <- c("female", "woman", "girl", "sister", "she", "her", "hers", "daughter")
sw <- weat(glove_math, S, T, A, B)

# extraction of effect size
weat_es(sw)
```

## A note about the effect size

By default, the effect size from the function `weat_es` is adjusted by the pooled standard deviaion (see Page 2 of Caliskan et al. 2007). The standardized effect size can be interpreted the way as Cohen's d (Cohen, 1988).

One can also get the unstandardized version (aka. test statistic in the original paper):

```{r}
weat_es(sw, standardize = FALSE)
```

The original implementation assumes equal size of `S` and `T`. This assumption can be relaxed by pooling the standard deviaion with sample size adjustment. The function `weat_es` does it when `S` and `T` are of different length.

Also, the effect size can be converted to point-biserial correlation (mathematically equivalent to the Pearson's product moment correlation).

```{r}
weat_es(sw, r = TRUE)
```

## Exact test

The exact test described in Caliskan et al. (2017) is also available. But it takes a long time to calculate.

```r
## Don't do it. It takes a long time and is almost always significant.
weat_exact(sw)
```

Instead, please use the resampling approximaton of the exact test. The p-value is very close to the reported 0.018.

```{r}
weat_resampling(sw)
```

## Example: Relative Norm Distance

This analysis reproduces the analysis in Garg et al (2018), namely Figure 1. Please note that `T` is not required.

```{r}
S <- c("janitor", "statistician", "midwife", "bailiff", "auctioneer", 
"photographer", "geologist", "shoemaker", "athlete", "cashier", 
"dancer", "housekeeper", "accountant", "physicist", "gardener", 
"dentist", "weaver", "blacksmith", "psychologist", "supervisor", 
"mathematician", "surveyor", "tailor", "designer", "economist", 
"mechanic", "laborer", "postmaster", "broker", "chemist", "librarian", 
"attendant", "clerical", "musician", "porter", "scientist", "carpenter", 
"sailor", "instructor", "sheriff", "pilot", "inspector", "mason", 
"baker", "administrator", "architect", "collector", "operator", 
"surgeon", "driver", "painter", "conductor", "nurse", "cook", 
"engineer", "retired", "sales", "lawyer", "clergy", "physician", 
"farmer", "clerk", "manager", "guard", "artist", "smith", "official", 
"police", "doctor", "professor", "student", "judge", "teacher", 
"author", "secretary", "soldier")
A <- c("he", "son", "his", "him", "father", "man", "boy", "himself", 
"male", "brother", "sons", "fathers", "men", "boys", "males", 
"brothers", "uncle", "uncles", "nephew", "nephews")
B <- c("she", "daughter", "hers", "her", "mother", "woman", "girl", 
"herself", "female", "sister", "daughters", "mothers", "women", 
"girls", "females", "sisters", "aunt", "aunts", "niece", "nieces"
)

garg_f1 <- rnd(googlenews, S, A, B)
```

Words such as "nurse", "midwife" and "librarian" are more associated with female, as indicated by the positive relative norm distance.

```{r}
sort(garg_f1$P, decreasing = TRUE)
```

The effect size is simply the sum of all relative norm distance values (Equation 3 in Garg et al. 2018). The more positive value indicates that words in S are more associated with `B`. As the effect size is negative, it indicates that the concept of occupation is more associated with `A`, i.e. male.

```{r}
rnd_es(garg_f1)
```

## Example: Relative Negative Sentiment Bias

This analysis attempts to reproduce the analysis in Sweeney & Najafian (2019). Please note that `T` is not required.

```{r}
S <- c("swedish", "irish", "mexican", "chinese", "filipino",
       "german", "english", "french", "norwegian", "american",
       "indian", "dutch", "russian", "scottish", "italian")
sn <- rnsb(glove_sweeney, S, bing_pos, bing_neg)
```

The analysis shows that `mexican`, `american`, `chinese` and `irish` are more likely to be associated with negative sentiment. (Please note that the numbers are different from the original paper; pending confirmation with the original authors)

```{r}
sort(sn$P)
```

The effect size from the analysis is the Kullback–Leibler divergence of P from the uniform distribution. (It is also substantially larger than the number reported in the original paper; pending confirmation with the original authors)

```{r}
rnsb_es(sn)
```

## Support for Quanteda Dictionary

`rnsb` supports quanteda dictionary as `S`. `rnd` and `weat` will support it later.

For example, `newsmap_europe` is an abridged dictionary from the package newsmap (Watanabe, 2018). The dictionary contains keywords of European countries and has two levels: regional level (e.g. Eastern Europe) and country level (e.g. Germany).

```{r}
require(quanteda)
newsmap_europe
```

Country-level analysis

```{r}
country_level <- rnsb(googlenews, newsmap_europe, bing_pos, bing_neg, levels = 2)
sort(country_level$P)
```

Region-level analysis

```{r}
region_level <- rnsb(googlenews, newsmap_europe, bing_pos, bing_neg, levels = 1)
sort(region_level$P)
```

Comparison of the two effect sizes. Please note the much smaller effect size from region-level analysis. It reflects the evener distribution of P acorss regions than across countries.

```{r}
rnsb_es(country_level)
rnsb_es(region_level)
```

## References

1. Badilla, P., Bravo-Marquez, F., & Pérez, J. (2020). WEFE: The word embeddings fairness evaluation framework. In Proceedings of the 29 th Intern. Joint Conf. Artificial Intelligence.
2. Brunet, M. E., Alkalay-Houlihan, C., Anderson, A., & Zemel, R. (2019, May). Understanding the origins of bias in word embeddings. In International Conference on Machine Learning (pp. 803-811). PMLR.
3. Caliskan, Aylin, Joanna J. Bryson, and Arvind Narayanan. "Semantics derived automatically from language corpora contain human-like biases." Science 356.6334 (2017): 183-186.
4. Cohen, J. (1988), Statistical Power Analysis for the Behavioral Sciences, 2nd Edition. Hillsdale: Lawrence Erlbaum.
5. Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic stereotypes. Proceedings of the National Academy of Sciences, 115(16), E3635-E3644.
6. McGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: the case of r and d. Psychological methods, 11(4), 386.
7. Rosenthal, R. (1991), Meta-Analytic Procedures for Social Research. Newbury Park: Sage
8. Sweeney, C., & Najafian, M. (2019, July). A transparent framework for evaluating unintended demographic bias in word embeddings. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (pp. 1662-1667).
9. Watanabe, K. (2018). Newsmap: A semi-supervised approach to geographical news classification. Digital Journalism, 6(3), 294-309.
